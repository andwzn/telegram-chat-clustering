{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/telegram_chat_clustering_2/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Import the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the cleaned dataset and check, if we retained the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581498, 38)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), \"../data/csv/cleaned_data.csv\")\n",
    "dtypes_path = os.path.join(os.getcwd(), '../data/auxiliary/cleaned_data_dtypes.json')\n",
    "\n",
    "# load datatypes\n",
    "with open(dtypes_path, 'r') as f:\n",
    "    dtypes_dict = json.load(f)\n",
    "    \n",
    "# isolate datetime and non-datetime columns\n",
    "datetime_cols = [col for col, dtype in dtypes_dict.items() if dtype == 'datetime64[ns]']\n",
    "dtype_dict_nodate = {col: dtype for col, dtype in dtypes_dict.items() if dtype != 'datetime64[ns]'}\n",
    "\n",
    "# load cleaned dataset using the types defined above\n",
    "df = pd.read_csv(path, low_memory=False, parse_dates=datetime_cols, dtype=dtype_dict_nodate)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Saved Data Types</th>\n",
       "      <th>Current Data Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chat_handle</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat_name</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat_type</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection_time</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fwd_from_chat_handle</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fwd_from_chat_id</th>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fwd_from_user_name</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_fwd</th>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_group_elem</th>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_reply</th>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_fwd_count</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_group_id</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_media_type</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_reactions</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_reactions_count</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_text</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_view_count</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply_to_message_id</th>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply_to_top_message_id</th>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sender_first_name</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sender_last_name</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sender_username</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telegram_chat_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telegram_message_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telegram_sender_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>television_message_id</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>television_original_message_id</th>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_author</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_description</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_title</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_url</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_webpage</th>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_image</th>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_video</th>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_document</th>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_text_lang</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_description_lang</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Saved Data Types Current Data Types\n",
       "chat_handle                              object             object\n",
       "chat_name                                object             object\n",
       "chat_type                                object             object\n",
       "collection_time                  datetime64[ns]     datetime64[ns]\n",
       "fwd_from_chat_handle                     object             object\n",
       "fwd_from_chat_id                          Int64              Int64\n",
       "fwd_from_user_name                       object             object\n",
       "is_fwd                                     bool               bool\n",
       "is_group_elem                              bool               bool\n",
       "is_reply                                   bool               bool\n",
       "message_date                     datetime64[ns]     datetime64[ns]\n",
       "message_fwd_count                       float64            float64\n",
       "message_group_id                        float64            float64\n",
       "message_media_type                       object             object\n",
       "message_reactions                        object             object\n",
       "message_reactions_count                 float64            float64\n",
       "message_text                             object             object\n",
       "message_view_count                      float64            float64\n",
       "reply_to_message_id                       Int64              Int64\n",
       "reply_to_top_message_id                   Int64              Int64\n",
       "sender_first_name                        object             object\n",
       "sender_last_name                         object             object\n",
       "sender_username                          object             object\n",
       "telegram_chat_id                          int64              int64\n",
       "telegram_message_id                       int64              int64\n",
       "telegram_sender_id                        int64              int64\n",
       "television_message_id                     int64              int64\n",
       "television_original_message_id            Int64              Int64\n",
       "webpage_author                           object             object\n",
       "webpage_description                      object             object\n",
       "webpage_title                            object             object\n",
       "webpage_url                              object             object\n",
       "is_webpage                                 bool               bool\n",
       "is_image                                   bool               bool\n",
       "is_video                                   bool               bool\n",
       "is_document                                bool               bool\n",
       "message_text_lang                        object             object\n",
       "webpage_description_lang                 object             object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatched data-types: 0\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe to compare the original datatypes and the datatypes of the imported dataframe\n",
    "dtypes_df = pd.DataFrame({\n",
    "    'Saved Data Types': dtypes_dict,\n",
    "    'Current Data Types': df.dtypes\n",
    "})\n",
    "display(dtypes_df)\n",
    "differences_df = dtypes_df[dtypes_df['Saved Data Types'] != dtypes_df['Current Data Types']]\n",
    "print(f\"Number of mismatched data-types: {differences_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1: Document Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create document embeddings based on a chats text. \n",
    "\n",
    "This is the most frequently used approach to vectorizing Telegram-Chats and will serve as a baseline for comparison in this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already downloaded. Loading...\n"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "model_dir = os.path.join(current_path, \"../data/models/\")\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "\n",
    "# Load or download the model\n",
    "if not os.path.isdir(model_path):\n",
    "    print(\"Model not found. Downloading...\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "else:\n",
    "    print(f\"Model already downloaded. Loading...\")\n",
    "    model = SentenceTransformer(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the baseline embeddings, we first define the functions we'll use to create the embeddings. To speed the process up, we'll also provide a function to do so in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings for a given text\n",
    "def get_embeddings(text, default_embedding, model):\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        return default_embedding\n",
    "    \n",
    "    return model.encode(text, convert_to_tensor=False)\n",
    "\n",
    "# Function to process each chunk of data\n",
    "def process_chunk(chunk, default_embedding, model):\n",
    "    embeddings = []\n",
    "    \n",
    "    for text in chunk:\n",
    "        embeddings.append(get_embeddings(text, default_embedding, model))\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the embeddings. \n",
    "To avoid redundant calculations, we'll only calculate the embeddings if we have not saved them yet. If they are already in our project, we'll simply load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the embeddings were already saved.\n",
    "current_path = os.getcwd()\n",
    "feature_0_path = os.path.join(current_path, \"../features/message_embeddings.csv\")\n",
    "already_vectorized = os.path.isfile(feature_0_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings already created. Loading Embeddings...\n"
     ]
    }
   ],
   "source": [
    "# calculate embeddings if they have not already been created\n",
    "\n",
    "if not already_vectorized:\n",
    "    \n",
    "    print(\"Embeddings not yet created. Vectorizing...\")\n",
    "    \n",
    "    # Create a copy of the original DataFrame\n",
    "    df_embeddings = df.copy()\n",
    "\n",
    "    # Set environment variable to control tokenizers parallelism\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "    # Define default embedding\n",
    "    default_embedding = np.zeros((model.get_sentence_embedding_dimension(),))\n",
    "\n",
    "    # Split DataFrame into chunks for parallel processing\n",
    "    num_chunks = 8 # one for each core. for some reason, three seems to be fast as well. \n",
    "    df_chunks = np.array_split(df_embeddings[\"message_text\"], num_chunks)\n",
    "\n",
    "    # Process each chunk in parallel\n",
    "    results = Parallel(n_jobs=num_chunks)(\n",
    "        delayed(lambda chunk: process_chunk(chunk, default_embedding))(chunk) for chunk in df_chunks\n",
    "    )\n",
    "\n",
    "    # Combine results into a single DataFrame\n",
    "    df_embeddings[\"embedding\"] = np.concatenate(results).tolist()\n",
    "    df_embeddings[\"embedding\"].head()\n",
    "    \n",
    "    # save the results as a csv-file\n",
    "    embedding_path = os.path.join(os.getcwd(), '../features/message_embeddings_2.csv')\n",
    "    df_embeddings.to_csv(embedding_path)\n",
    "    print(df_embeddings.shape())\n",
    "    \n",
    "else:\n",
    "    # loading the whole dataframe takes about 45min. Instead we'll load only the embedding column and add it to the dataframe we loaded earlier\n",
    "    print(\"Embeddings already created. Loading Embeddings...\") \n",
    "    feature = ['embedding']\n",
    "    embeddings = pd.read_csv(feature_0_path, skipinitialspace=True, usecols=feature)\n",
    "    df_embeddings = df.copy()\n",
    "    df_embeddings[\"embedding\"] = embeddings\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1: Strucutral Equivalence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We construct an adjacency matrix representing the frequency of forwarded messages from one chat to another in our dataset.\n",
    "\n",
    "2. We correlate the rows of the matrix, ignoring diagonals to produce a correlation matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create the Chat/Feature Matrix\n",
    "\n",
    "An adjacency matrix is a standard representation of a graph where each cell indicates the number of connections between nodes. In our case, the columns represent the source chats of messages, and the row indices represent the chats in our dataset.\n",
    "\n",
    "Due to limitations in the data collection process, the current adjacency matrix does not capture all forward-based relationships between chats. Instead, it only reflects the incoming connections observed within the data collection timeframe.\n",
    "\n",
    "To create a comprehensive adjacency matrix, we will:\n",
    "\n",
    "1. Isolate Rows with forwarded messages\n",
    "\n",
    "\n",
    "2. Construct the Adjacency Matrix\n",
    "\n",
    "\n",
    "3. Add Chats with no forwarded messages\n",
    "\n",
    "We'll start with isolating rows with forwarded messages and create the initial adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate rows that contain messages forwarded from a public chat\n",
    "fwd_messages = df[~(pd.isna(df[\"fwd_from_chat_id\"]))]\n",
    "\n",
    "# Create the adjacency matrix \n",
    "adj_matrix = fwd_messages.pivot_table(\n",
    "                            index='telegram_chat_id', \n",
    "                            columns='fwd_from_chat_id', \n",
    "                            aggfunc='size', # count the number of occurrences of each combination of telegram_chat_id and fwd_from_chat_id\n",
    "                            fill_value=0) # fills all cells with no co-occurances of chat and source-chat with 0\n",
    "adj_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check, if we have chats without any forwarded messages in our dataset and if they are already in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group messages by chat they were sent in\n",
    "grouped = df.groupby(\"telegram_chat_id\")\n",
    "\n",
    "# get the chat ids of all chats, that have 0 messages forwarded from public chats\n",
    "def all_nans(series):\n",
    "    return series.isna().all()\n",
    "no_fwd_chats = grouped[\"fwd_from_chat_id\"].apply(all_nans)\n",
    "no_fwd_chats = no_fwd_chats[no_fwd_chats==True].index\n",
    "\n",
    "# check if the Adjacency Matrix already contains the chats we identified\n",
    "index_adj_matrix = adj_matrix.index\n",
    "in_matrix = []\n",
    "not_in_matrix = []\n",
    "\n",
    "for index in no_fwd_chats:\n",
    "    if index in (index_adj_matrix):\n",
    "        in_matrix.append(index)\n",
    "    else:\n",
    "        not_in_matrix.append(index)\n",
    "        \n",
    "print(f\"{len(in_matrix)}/{len(no_fwd_chats)} chats without forwarded messages are already in the matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll add rows for chats containing no forwarded messages to the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the adjacency matrix for non-forward chats\n",
    "non_fwd_adj_matrix = pd.DataFrame(index=not_in_matrix, columns=adj_matrix.columns)\n",
    "non_fwd_adj_matrix.fillna(0,inplace=True) # set all values to 0, as these chats have no connections.\n",
    "\n",
    "# add them to the initial matrix\n",
    "adj_matrix_combined = pd.concat([adj_matrix, non_fwd_adj_matrix], axis=0)\n",
    "adj_matrix_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, we need to check if each chat is represented in our adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_chat_count = df[\"telegram_chat_id\"].nunique()\n",
    "adj_matrix_chat_count = adj_matrix_combined.shape[0]\n",
    "print(f\"Number of chats in dataset: {initial_chat_count}\")\n",
    "print(f\"Number of chats in Adjacency Matrix: {adj_matrix_chat_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply logarithmic scaling to the matrix\n",
    "adj_matrix_log_scaled = np.log1p(adj_matrix_combined)  # np.log1p is log(x + 1) to handle zeros\n",
    "\n",
    "# Convert back to DataFrame if needed\n",
    "adj_matrix_log_scaled = pd.DataFrame(adj_matrix_log_scaled, \n",
    "                                     index=adj_matrix_combined.index, \n",
    "                                     columns=adj_matrix_combined.columns)\n",
    "\n",
    "\n",
    "# Display the normalized adjacency matrix\n",
    "plt.figure(figsize=(30, 10))\n",
    "sns.heatmap(adj_matrix_log_scaled, annot=False, cmap='coolwarm', vmax=4)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix_one_hot = adj_matrix_combined.map(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "# Display the one hot encoded adjacency matrix\n",
    "plt.figure(figsize=(30, 10))\n",
    "sns.heatmap(adj_matrix_one_hot, annot=False, cmap='gist_yarg')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = adj_matrix_one_hot.columns\n",
    "only_once = []\n",
    "for col in cols:\n",
    "    if (adj_matrix_one_hot[col].value_counts().loc[1] == 1): # get all columns that have only one connection to a chat and drop them\n",
    "        only_once.append(col)\n",
    "\n",
    "adj_matrix_one_hot_multiple = adj_matrix_one_hot.drop(axis=1, labels=only_once)\n",
    "adj_matrix_one_hot_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=11, random_state=1, n_init=\"auto\").fit(adj_matrix_one_hot_multiple)\n",
    "clusters = kmeans.labels_\n",
    "pd.Series(clusters).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram-chat-clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
